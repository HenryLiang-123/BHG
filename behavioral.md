1. Time you failed something?

- Technical interview -> was confident in my abilities since I spent considerable amount of time going over major ML concepts
- During interview -> quickly stumped.
    - went a lot deeper into concepts
    - asked about each ML algorithm pros and cons, and gave me scenarios.
    - asked about evaluation metrics of each algo, and pros and cons, and when to use
- Realized I only scratched the surface of ML during my studies.
    - Taken steps to increase knowledge by
        - developing intuition about how the algo learns
        - look into specific use cases and determine why they would be useful or unuseful in a scenario with a certain distribution of data
        - Look into how we can manipulate the data in order to make a certain algorithm work.
        - Learn about evaluation metrics of the algo / pros and cons
        - combine to develop understanding of entire model building process

2. Why BHG?

During my academic career, I have developed an appreciation for the tremendous value of data. There are many parameters, parameters that you have never even dreamed of, that the data can tell you about a situation. The amount of available data that BHG has and the endless number of insights I can draw from it excites me. Having had extensive experience in data analytics, including a project where my team and I analyzed
point of sales data from Dillard's stores, my expertise in SQL, Python, and data analysis will enable me to draw
insights from data as well as build novel solutions with the latest machine learning techniques. I enjoy being a part of new technologies and trying out innovative solutions, and I believe working at BHG will allow me to employ these new technologies building actionable solutions to help BHG make better and more data driven business decisions, such as whether or not to give someone a loan.




    - To realize my goals
        - Developed extensive experience in data science.
        - Project working with point of sales data from Dillard's stores
        - Interacted extensively with SQL and Python to clean more than 160 million lines of data, and modeling techniques like clustering to cluster similar items to build a recommendation engine.
        - This project gave me the experience neccessary to integrate quickly into Shure's data science team and work on impactful projects from the start.

3. Why DS?

- Recent news: big data, AI, ML
- Data holds great value: recommendation systems built on user data is helping retail companies rake in billions, and the amount of data will only increase.
    - To untrained eye, it us meaningless.
    - Thus, people who are able to translate data into insights / plain English are critical to many industries
- With data science, I can turn raw data into information that can influence pivotal decisions
- Working on projects like developing use cases for REFIT (Northwestern's platform that deploys machine learning models to IoT data) and exercise form tracker for my startup
    - Showed the impact data can have.
    - Will be able to utilze data from the network of Divvy bikes to predict the number of trips at each station
    - able to determine if someone is doing an exercise correctly using videos of people exercising
- Being able to create impact from a mumbo jumbo of data excites me, and I cant wait to see what the future holds for data science.

4. What strengths will you bring to this role?

- Bring expertise in working with the latest data science technologies and machine learning methods to the team.
    - Most recent project involves:
        - Taking several million lines of time series data generated by Divvy bikes
        - external data like weather
        - building a model to predict the number of trips at each bike station in the next hour.
        - Also involves simulating data streaming and deploying the model / data pipeline on AWS and NU's REFIT.
    - Another project is my startup FitX
        - Combine fitness and AI
        - I am building a exercise form tracker using Python and its various deep learning libraries, such as openCV, pytorch, OpenPose, and so on
        - The program tracks body keypoints such as joints and limbs in either live video or recorded videos, and checks if the exercise is performed within tolerance.
        - The tolerances are first calculated based on an array of training videos, then are continously updated basedon the individual user's body anatomy.
        - I also built a feedback system that gives recommendations on how to improve the exercise based onframe by frame performance.
- During these projects
    - worked extensively with python / state of the art ML libraries to
        - generate viz
        - conduct analysis
        - build and deploy models
    - Working on startup allowed me to dig deep into concepts and intricacies of CV and applying it to suit my needs
    - Working on a team in these two major projects have enabled me to become a more effective team player and communicator.

5. What do you hope to gain from this experience?

- Interested in applying machine learning techniques to non-tech fields such as finance
    - Want to deepen my experience working through the full data lifecycle, including gathering, joining, cleaning, modeling, etc.
    - enjoy being a part of new technologies and trying out innovative solutions, 
    - I want to use those technologies and solutions to help build actionable solutions.
- I also want to learn what it is like using technologies like Python, TensorFlow, OpenCV, SQL in a business setting
    - not all the data is necessarily clean enough to directly draw insights from.
    - I want to immerse myself into the real-world machine learning workflow.
- Finally, I want to experience working with an entire team of data scientists to challenge and deepen my data science knowledge and learn the "tricks of the trade" so to speak.

6. Projects and difficulties

- One of my projects is my startup FitX
    - Combine fitness and AI
    - I am building a exercise form tracker using Python and its various deep learning libraries, such as openCV, pytorch, OpenPose, and so on
    - The program tracks body keypoints such as joints and limbs in either live video or recorded videos, and checks if the exercise is performed within tolerance.
    - The tolerances are first calculated based on an array of training videos, then are continously updated basedon the individual user's body anatomy.
    - I also built a feedback system that gives recommendations on how to improve the exercise based onframe by frame performance.
- Biggest difficulty
    - Sourcing good data
    - Although there are many videos of people training in the gym, many of them vary in angle, lighting, quality, and direction. 
    - It was very difficult to find videos of people filming straight on with at least decent lighting or video quality.
    - This significantly slowed the tolerance range computation, and my team and I are working on a new algorithm that uses the pattern of the movement of keypoints to determine if an exercise is done correctly. I can't go into detail because we are filing a patent, but it is quite exciting!

7. A time you went above and beyond?







1. Most exciting thing in tech and how it applies to company

- One of the most exciting tech is IoT and predictions using it. (combination of IoT and AI)
    - actually related to one of my projects, where we gather data from a network of divvy bikes stations and predict the number of trips at each station in the next hour. There is a whole pipeline to the data streaming, storage, and model deployment
    - I think the combination of IoT and AI can be very exciting to Shure.
        - Shure makes audio electronics, and most of the time audio electronics are not stand alone products. 
        - In a studio, you would have mic, amp, sound mixers, speakers, etc
        - By using IoT and AI, you could connect all of these devices, which allows data sharing between them. For instance, if you adjust the tone of the audio in the studio, that adjustment data can be fed into a prediction system to predict how other equipment should be adjusted to match the specs in order to produce the best results.

2. Project and difficulty

- One of my projects is my startup FitX
    - Combine fitness and AI
    - I am building a exercise form tracker using Python and its various deep learning libraries, such as openCV, pytorch, OpenPose, and so on
    - The program tracks body keypoints such as joints and limbs in either live video or recorded videos, and checks if the exercise is performed within tolerance.
    - The tolerances are first calculated based on an array of training videos, then are continously updated basedon the individual user's body anatomy.
    - I also built a feedback system that gives recommendations on how to improve the exercise based onframe by frame performance.
- Biggest difficulty
    - Sourcing good data
    - Although there are many videos of people training in the gym, many of them vary in angle, lighting, quality, and direction. 
    - It was very difficult to find videos of people filming straight on with at least decent lighting or video quality.
    - This significantly slowed the tolerance range computation, and my team and I are working on a new algorithm that uses the pattern of the movement of keypoints to determine if an exercise is done correctly. I can't go into detail because we are filing a patent, but it is quite exciting!

3. Tech stack

- Extensively use Python and its libraries like Pandas, Numpy, Scikit Learn, Pytorch to do data analysis, data viz, machine learning, and computer vision related work. Very comfortable with using the above libraries. I also use R to do statistical analysis. 

- I use SQL extensively in my projects because of the large datasets; I have them stored on a remote PostGreSQL server, and access it when I need.

4. 3 things in a ML project

- Domain knowledge
    - Needed to understand the overarching question of why
    - Can greatly speed up understanding of variables in the data and the relationship between each variable.
    - Understanding relationships can help with feature selection and building more robust models and choosing the right evaluation metrics.
    - also makes sure everyone on the team is on board with the goal of the project.


- Data cleaning
    - Approximately 80% of time in a data science project is spent on cleaning data
    - Having clean data will ensure we can use the technologies like Python, Pandas, SciKit Learn without any issues
    - Can also deal with missing data to help create a more complete dataset which in turn helps the model learn the variations better
    - furthermore, it allows us to obtain an accurate dataset that can generate reliable visualizations, models, and in turn business decisions.

- researching the correct model
    - Can't just randomly fit models
    - Depending on the problem statement, we have to determine if we're going to use
        - supervised / unsupervised
        - classification / regression
    - Having this knowledge is essential to the model building process and creating a model that is robust and actually predicts what is needed and solves the problem at hand.

